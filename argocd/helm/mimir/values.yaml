mimir-distributed:
  alertmanager:
    enabled: false
    replicas: 1

  distributor:
    replicas: 1

  ingester:
    replicas: 1

  overrides_exporter:
    enabled: true
    replicas: 1

  ruler:
    enabled: true
    replicas: 1

  querier:
    replicas: 1

  query_frontend:
    replicas: 1

  query_scheduler:
    enabled: true
    replicas: 1

  store_gateway:
    replicas: 1
    zoneAwareReplication:
      enabled: false

  compactor:
    replicas: 1

  minio:
    enabled: true
    mode: standalone
    rootUser: grafana-mimir
    rootPassword: supersecret

  nginx:
    enabled: false

  gateway:
    enabledNonEnterprise: true
    replicas: 1

  metaMonitoring:
    dashboards:
      enabled: true
      annotations:
        k8s-sidecar-target-directory: /tmp/dashboards/Mimir Dashboards
      labels:
        grafana_dashboard: "1"

    serviceMonitor:
      enabled: true
      labels:
        release: "kube-prometheus-stack"

    # Rules for the Prometheus Operator
    prometheusRule:
      enabled: true
      mimirAlerts: true
      mimirRules: true
      annotations: {}
      labels:
        grafana_alert: "1"
      # -- prometheusRule namespace. This should be the namespace where the Prometheus Operator is installed,
      # unless the Prometheus Operator is set up to look for rules outside its namespace
      namespace: kube-prometheus-stack
      # -- Contents of Prometheus rules file
      groups:
        - name: mimir_api_1
          rules:
            - expr: histogram_quantile(0.99, sum(rate(cortex_request_duration_seconds_bucket[1m]))
                by (le, cluster, job))
              record: cluster_job:cortex_request_duration_seconds:99quantile
            - expr: histogram_quantile(0.50, sum(rate(cortex_request_duration_seconds_bucket[1m]))
                by (le, cluster, job))
              record: cluster_job:cortex_request_duration_seconds:50quantile
            - expr: sum(rate(cortex_request_duration_seconds_sum[1m])) by (cluster, job) / sum(rate(cortex_request_duration_seconds_count[1m]))
                by (cluster, job)
              record: cluster_job:cortex_request_duration_seconds:avg
            - expr: sum(rate(cortex_request_duration_seconds_bucket[1m])) by (le, cluster, job)
              record: cluster_job:cortex_request_duration_seconds_bucket:sum_rate
            - expr: sum(rate(cortex_request_duration_seconds_sum[1m])) by (cluster, job)
              record: cluster_job:cortex_request_duration_seconds_sum:sum_rate
            - expr: sum(rate(cortex_request_duration_seconds_count[1m])) by (cluster, job)
              record: cluster_job:cortex_request_duration_seconds_count:sum_rate

    # metaMonitoringAgent configures the built in Grafana Agent that can scrape metrics and logs and send them to a local or remote destination
    grafanaAgent:
      # -- Controls whether to create PodLogs, MetricsInstance, LogsInstance, and GrafanaAgent CRs to scrape the
      # ServiceMonitors of the chart and ship metrics and logs to the remote endpoints below.
      # Note that you need to configure serviceMonitor in order to have some metrics available.
      enabled: false

      # -- Controls the image repository and tag for config-reloader and grafana-agent containers in the meta-monitoring
      # StatefulSet and DaemonSet created by the grafana-agent-operator. You can define one or both sections under imageRepo.
      # If a section is defined, you must pass repo, image and tag keys.
      imageRepo:
      #  configReloader:
      #    repo: quay.io
      #    image: prometheus-operator/prometheus-config-reloader
      #    tag: v0.47.0
      #  grafanaAgent:
      #    repo: docker.io
      #    image: grafana/agent
      #    tag: v0.29.0

      # -- Controls whether to install the Grafana Agent Operator and its CRDs.
      # Note that helm will not install CRDs if this flag is enabled during an upgrade.
      # In that case install the CRDs manually from https://github.com/grafana/agent/tree/main/production/operator/crds
      installOperator: false

      logs:
        enabled: true

      metrics:
        enabled: true

        # -- Default destination for metrics. The config here is translated to remote_write
        # configuration to push metrics to this Prometheus-compatible remote. Optional.
        # Note that you need to configure serviceMonitor in order to have some metrics available.
        #
        # If you leave the metamonitoring.grafanaAgent.metrics.remote.url field empty,
        # then the chart automatically fills in the address of the GEM gateway Service
        # or the Mimir NGINX Service.
        #
        # If you have deployed Mimir, and metamonitoring.grafanaAgent.metrics.remote.url is not set,
        # then the metamonitoring metrics are be sent to the Mimir cluster.
        # You can query these metrics using the HTTP header X-Scope-OrgID: metamonitoring
        #
        # If you have deployed GEM, then there are two cases:
        # * If are using the 'trust' authentication type (mimir.structuredConfig.auth.type: trust),
        #   then the same instructions apply as for Mimir.
        #
        # * If you are using the enterprise authentication type (mimir.structuredConfig.auth.type=enterprise, which is also the default when enterprise.enabled=true),
        #   then you also need to provide a Secret with the authentication token for the tenant.
        #   The token should be to an access policy with metrics:read scope.
        #   To set up the Secret, refer to https://grafana.com/docs/helm-charts/mimir-distributed/latest/run-production-environment-with-helm/monitor-system-health/
        #   Assuming you are using the GEM authentication model, the Helm chart values should look like the following example.
        #
        # remote:
        #   auth:
        #     username: metamonitoring
        #     passwordSecretName: gem-tokens
        #     passwordSecretKey: metamonitoring
        remote:
          # -- Full URL for Prometheus remote-write. Usually ends in /push.
          # If you leave the url field empty, then the chart automatically fills in the
          # address of the GEM gateway Service or the Mimir NGINX Service.
          url: ''

          # -- Used to add HTTP headers to remote-write requests.
          headers: {}
          auth:
            # -- Basic authentication username. Optional.
            username: ''

            # -- The value under key passwordSecretKey in this secret will be used as the basic authentication password. Required only if passwordSecretKey is set.
            passwordSecretName: ''
            # -- The value under this key in passwordSecretName will be used as the basic authentication password. Required only if passwordSecretName is set.
            passwordSecretKey: ''

        # -- Additional remote-write for the MetricsInstance that will scrape Mimir pods. Follows the format of .remote.
        additionalRemoteWriteConfigs: []

        scrapeK8s:
          # -- When grafanaAgent.enabled and serviceMonitor.enabled, controls whether to create ServiceMonitors CRs
          # for cadvisor, kubelet, and kube-state-metrics. The scraped metrics are reduced to those pertaining to
          # Mimir pods only.
          enabled: true

          # -- Controls service discovery of kube-state-metrics.
          kubeStateMetrics:
            namespace: kube-system
            labelSelectors:
              app.kubernetes.io/name: kube-state-metrics

        # -- The scrape interval for all ServiceMonitors.
        scrapeInterval: 60s

      # -- Sets the namespace of the resources. Leave empty or unset to use the same namespace as the Helm release.
      namespace: ''

      # -- Labels to add to all monitoring.grafana.com custom resources.
      # Does not affect the ServiceMonitors for kubernetes metrics; use serviceMonitor.labels for that.
      labels: {}

      # -- Annotations to add to all monitoring.grafana.com custom resources.
      # Does not affect the ServiceMonitors for kubernetes metrics; use serviceMonitor.annotations for that.
      annotations: {}

      # -- SecurityContext of Grafana Agent pods. This is different from the SecurityContext that the operator pod runs with.
      # The operator pod SecurityContext is configured in the grafana-agent-operator.podSecurityContext value.
      # As of mimir-distributed 4.0.0 the Agent DaemonSet that collects logs needs to run as root and be able to access the
      # pod logs on each host. Because of that the agent subchart is incompatible with the PodSecurityPolicy of the
      # mimir-distributed chart and with the Restricted policy of Pod Security Standards https://kubernetes.io/docs/concepts/security/pod-security-standards/
      podSecurityContext:
      #  fsGroup: 10001
      #  runAsGroup: 10001
      #  runAsNonRoot: true
      #  runAsUser: 10001
      #  seccompProfile:
      #    type: RuntimeDefault

      # -- SecurityContext of Grafana Agent containers. This is different from the SecurityContext that the operator container runs with.
      # As of mimir-distributed 4.0.0 the agent subchart needs to have root file system write access so that the Agent pods can write temporary files where.
      # This makes the subchart incompatible with the PodSecurityPolicy of the mimir-distributed chart.
      containerSecurityContext:
      #  allowPrivilegeEscalation: false
      #  runAsUser: 10001
      #  capabilities:
      #    drop: [ALL]